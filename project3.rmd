---
title: "Project 3"
author: "Rachel Fellman & Sabrina Dahl"
params: 
  Ed: 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
```

# Introduction
The "diabetes" dataset (as read in below) consists of 253,680 responses to 21 variables of the Behavioral Risk Factor Surveillance System survey conducted by the CDC in 2015. We will be focusing on the Diabetes_binary as our response variable where 0 indicates no diabetes, and 1 indicates either prediabetes or diabetes.  
We will be exploring how Body Mass Index (BMI), Age, Income, healthcare (AnyHealthcare), and Mental Health (MentHlth) affects our response variable and any trends between them. Age is scaled from 1-13 (1=18-24, 9=60-64, and 13= 80 or older). Income is scaled from 1-8 (1 is less than 10,000 dollars, 5 less than 35,000, and 8 is 75,000 or more). Healthcare is an indication of whether they have any form of healthcare with 0 is no and 1 is yes. Mental Health is the days of poor mental health on a scale from 1-30.  
We will also be exploring the HvyAlcoholConsump, Sex, NoDocbcCost, and PhysHlth variables. Heavy Alcohol Consumption would be greater than or equal to 14 drinks a week for a man and greater than or equal to seven drinks for a woman with 0 indicating no, and 1 indicating yes. For Sex, 0 indicates female and 1 indicates male. NoDocbcCost indicates whether the individual needed to go to the doctor at any time in the past 12 months but did not go because of cost with 0 being no and 1 being yes. PhysHlth is the days with physical illness or injury in the past 30 days on a scale from 1-30.  
Exploratory Data Analysis (EDA) is important to ensure we understand the data so results are created with intent. Checking for missing data and outliers is important so that any skew to the data can be avoided, and potentially different approaches can be used for more representative results. We will then fit multiple model types to the training set and determine the best model for predicting the Diabetes_binary variable within each model type. Those *best* models will then each be applied to the test set to determine which model type is best at predicting the Diabetes_binary variable. This will be done for each level of education, so that a model will be selected that best predicts whether an individual has diabetes/prediabetes or not within their education level. The education levels will be split as follows: 1= never attended-Grade 8, 3=Grade 9-11, 4=Grade 12-High School Graduate, 5=College Years 1-3, and 6=College year 4-College Graduate.  
# Data

We will start by reading in the data with the `read_csv` function with a relative path. 

```{r, message=FALSE}
diabetes <- read_csv("diabetes_binary_health_indicators_BRFSS2015.csv")
```

Next we will combine the 1 and 2 groups in the `Education` variable into a new group. We will do this using the `mutate` and `ifelse` functions. The new value for the 1 and 2 groups will just be 1, so `Education` can equal 1, 3, 4, 5, or 6.

```{r}
diabetes.1 <- diabetes %>% 
  mutate(Education = ifelse(Education < 3, 1, Education))
```

# Summarizations

We will start by doing some exploratory data analysis on the full data set. 

Since we will be creating models for different education levels, we will split up the data into smaller data set for each of the 5 education levels to do EDA. We will do this using our parameters
```{r}
#create subsetted data set for each level of education using the params.
diabetes.ed <- diabetes.1 %>% 
  filter(Education == params$Ed)
```  

We will also look at the graph of diabetes proportion vs their Physical Health. 
```{r}
#group by PhysHlth to create graph of proportion of people with diabetes at each number of days with illness/injury
physHlth.sum <- diabetes.ed %>% 
  group_by(PhysHlth) %>% 
  summarise(proportion.diabetes = mean(Diabetes_binary), n = n())
# create plot
ggplot(physHlth.sum, aes(x = PhysHlth, y = proportion.diabetes, size = n)) +
  geom_point(stat = "identity")+ 
#add title and labels
  xlab("Physical Illness/Injury (# of days)")+
  labs(title = "Proportion of People with Diabetes", subtitle = "vs the number of days they had a Physical illness/injury the last 30 days")
```  

```{r}
#Create a table with the proportions of people with/without diabetes vs whether they heavily drink or not
tab.Alc<- table(diabetes.ed$Diabetes_binary, diabetes.ed$HvyAlcoholConsump)
#Add Column and row names
colnames(tab.Alc)=c("No Heavy Alcohol Consumption", "Heavy Alcohol Consumption")
rownames(tab.Alc)=c("No Diabetes", "Pre-/Diabetes")
tab.Alc #printing
```  

```{r}
#create a new factor variable of the Sex variable
Gender <- factor(ifelse(diabetes.ed$Sex>0,"Female","Male"))
#group by HvyAlcoholConsump to create graph of proportion of people with diabetes vs whether they drink heavily or not and their sex
Alc.sum <- diabetes.ed %>% 
  mutate(proportion.diabetes = mean(Diabetes_binary), Gender) %>%
  group_by(HvyAlcoholConsump)
#create graph
ggplot(Alc.sum, aes(x=HvyAlcoholConsump, y=proportion.diabetes))+
  geom_bar(stat="identity", aes(fill=Gender), position="stack")
```

```{r}
#Create a table with the proportions of people with/without diabetes vs whether they had to avoid the doctor the last 30 days due to costs
tab.Doc<- prop.table(table(diabetes.ed$Diabetes_binary, diabetes.ed$NoDocbcCost))
#Add Column and row names
colnames(tab.Doc)=c("Not Avoid", "Avoid Doc")
rownames(tab.Doc)=c("No Diabetes", "Pre-/Diabetes")
tab.Doc #printing
```

```{r}
#group by NoDocbcCost to create graph of proportion of people with diabetes vs whether they avoided the doctor or not and their sex
Doc.sum <- diabetes.ed %>% 
  mutate(proportion.diabetes = mean(Diabetes_binary), Gender) %>%
  group_by(NoDocbcCost)
#create graph
ggplot(Doc.sum, aes(x=NoDocbcCost, y=proportion.diabetes))+
  geom_bar(stat="identity", aes(fill=Gender),position="stack")
```

# Modeling

Before doing any modeling we will split the data into a training and test set using the `createDataPartition` function from the `caret` package. The test/train data will be split with a 70/30 ratio.

```{r}
# makes Diabetes_binary variable a factor
diabetes.ed$Diabetes_binary <- as_factor(diabetes.ed$Diabetes_binary)
#make things reproducible with set.seed (I have no idea what number we are supposed to put here because I don't really know what this function does)
set.seed(90)
#create index
train.index <- createDataPartition(diabetes.ed$Diabetes_binary, p = .7, list = FALSE)
#create train and test sets
diabetes.train <- diabetes.ed[train.index, ]
diabetes.test <- diabetes.ed[-train.index, ]
```

## Log Loss  

## Logistic Regression  
```{r}
diabetes.train.log <- diabetes.train %>% 
  mutate(Diabetes_binary = as_factor(ifelse(Diabetes_binary == 1, "yes", "no")))
diabetes.test.log <- diabetes.test %>% 
  mutate(Diabetes_binary = as_factor(ifelse(Diabetes_binary == 1, "yes", "no")))
```

## Lasso  
Lasso regression can be an extension of linear regression or logistic regression. Here, we will use it with a logistic regression model since we are working with a categorical response variable. Lambda represents shrinkage. As we increase lambda, the variance decreases and bias increases. We want the lowest amount of variance without introducing a lot of bias to the model.  
We will be fitting the model using the train function from the caret package. The glmnet method will ensure we are creating a lasso model.  
```{r}
#create lasso logistic regression model
fit.lasso <- train(Diabetes_binary ~ BMI+Age+Income+MentHlth+Sex+PhysHlth+ AnyHealthcare+HvyAlcoholConsump+NoDocbcCost, 
                   data= diabetes.train.log,
                   #select glmnet method
                   method= "glmnet",
                   #do cross validation
                   trControl= trainControl(method = "cv",
                                           number=5,
                                           summaryFunction = mnLogLoss,
                                           classProbs = TRUE),
                   #calculate log loss metric
                   metric= "logLoss",
                   #add tuning parameters
                   tuneGrid= expand.grid(alpha=1, lambda= seq(0,1, by=0.1)))
#print results of lasso logistic regression model
print(fit.lasso)
```
Now we will select our best Lasso model using the `Log Loss` metric.
```{r}
best.lasso <- fit.lasso$results %>% 
  mutate(lambda = lambda, min = min(logLoss)) %>% 
  filter(logLoss == min)
paste("The best classification model is lambda=",best.lasso$lambda," ")
```

## Classification Trees  
A classification tree is used to predict what class each region is using the most prevalent class (since we have a categorical response) as the prediction. The cp (complexity Parameter) is used for determining the size of the classification tree. It is imposes a penalty when the tree has too many splits, and the higher the cp the smaller the tree is.  
We will be fitting the model using the train function from the caret package. The rpart method will ensure we are creating a classification tree.  
```{r}
#create classification tree model
fit.classtree <- train(Diabetes_binary ~ BMI+Age+Income+MentHlth+Sex+PhysHlth+ AnyHealthcare+HvyAlcoholConsump+NoDocbcCost, 
                   data= diabetes.train.log,
                   #select rpart method
                   method= "rpart",
                   #do cross validation
                   trControl= trainControl(method = "cv",
                                           number=5,
                                           summaryFunction = mnLogLoss,
                                           classProbs = TRUE),
                   #calculate log loss metric
                   metric= "logLoss",
                   #add tuning parameters
                   tuneGrid= data.frame(cp= seq(0,1, by=0.001)))
#print results of classification tree model
print(fit.classtree)
```
Now we will select our best Classification Tree model using the `Log Loss` metric.
```{r}
best.classtree <- fit.classtree$results %>% 
  mutate(cp = cp, min = min(logLoss)) %>% 
  filter(logLoss == min)
paste("The best classification model is cp=",best.classtree$cp," ")
```

## Random Forest Models  

## Logistic Model Tree  

## Partial Least Squares Model  
Partial Least Squares is a dimension reduction strategy-determines which predictors are highly correlated and determines the best model to use that covers the most variance with the least amount of principal components. The PLS identifies principal components that summarizes the original predictors and and are related to the response variable. The ncomp tuning parameter represents the number of principal components included in the model.  
We will be fitting the model using the train function from the caret package. The pls method will ensure we are creating a partial least squares model.  
```{r}
#create PLS model
fit.pls <- train(Diabetes_binary ~ BMI+Age+Income+MentHlth+Sex+PhysHlth+ AnyHealthcare+HvyAlcoholConsump+NoDocbcCost, 
                 data= diabetes.train.log,
                 #select pls method
                 method= "pls",
                 #center and sclae the data
                 preProcess=c("center","scale"),
                 #do cross validation
                 trControl= trainControl(method = "cv",
                                           number=5,
                                         summaryFunction = mnLogLoss,
                                         classProbs = TRUE),
                 #calculate log loss metric
                 metric= "logLoss",
                 #add tuning parameters
                 tuneGrid= data.frame(ncomp=1:9))
#print
print(fit.pls)
```
Now we will select our best PLS model using the `log Loss` metric.
```{r}
best.pls <- fit.pls$results %>% 
  mutate(ncomp = ncomp, min = min(logLoss)) %>% 
  filter(logLoss == min)
paste("The best classification model is ncomp=",best.pls$ncomp," ")
```

# Final Model Selection  
```{r, warning=FALSE}
a
b
c
d<- confusionMatrix(data = diabetes.test.log$Diabetes_binary, reference = predict(fit.lasso, newdata = diabetes.test.log))
e<- confusionMatrix(data = diabetes.test.log$Diabetes_binary, reference = predict(fit.classtree, newdata = diabetes.test.log))
f<- confusionMatrix(data = diabetes.test.log$Diabetes_binary, reference = predict(fit.pls, newdata = diabetes.test.log))
```  

```{r}
name<- c("fit.log3", "fit.rf", "fit.lmt", "fit.lasso", "fit.classtree","fit.pls")
accuracy <- c(a[[3]][1],b[[3]][1],c[[3]][1],d[[3]][1],e[[3]][1],f[[3]][1])
all.fits<- tibble(name, accuracy)
```