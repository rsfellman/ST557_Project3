---
title: "Project 3"
author: "Rachel Fellman & Sabrina Dahl"
params: 
  Ed: 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
```

# Introduction
The "diabetes" dataset (as read in below) consists of 253,680 responses to 21 variables of the Behavioral Risk Factor Surveillance System survey conducted by the CDC in 2015. We will be focusing on the Diabetes_binary as our response variable where 0 indicates no diabetes, and 1 indicates either prediabetes or diabetes.  
We will be exploring how Body Mass Index (BMI), Age, Income, healthcare (AnyHealthcare), and Mental Health (MentHlth) affects our response variable and any trends between them. Age is scaled from 1-13 (1=18-24, 9=60-64, and 13= 80 or older). Income is scaled from 1-8 (1 is less than 10,000 dollars, 5 less than 35,000, and 8 is 75,000 or more). Healthcare is an indication of whether they have any form of healthcare with 0 is no and 1 is yes. Mental Health is the days of poor mental health on a scale from 1-30.  
We will also be exploring the HvyAlcoholConsump, Sex, NoDocbcCost, and PhysHlth variables. Heavy Alcohol Consumption would be greater than or equal to 14 drinks a week for a man and greater than or equal to seven drinks for a woman with 0 indicating no, and 1 indicating yes. For Sex, 0 indicates female and 1 indicates male. NoDocbcCost indicates whether the individual needed to go to the doctor at any time in the past 12 months but did not go because of cost with 0 being no and 1 being yes. PhysHlth is the days with physical illness or injury in the past 30 days on a scale from 1-30.  
Exploratory Data Analysis (EDA) is important to ensure we understand the data so results are created with intent. Checking for missing data and outliers is important so that any skew to the data can be avoided, and potentially different approaches can be used for more representative results. We will then fit multiple model types to the training set and determine the best model for predicting the Diabetes_binary variable within each model type. Those *best* models will then each be applied to the test set to determine which model type is best at predicting the Diabetes_binary variable. This will be done for each level of education, so that a model will be selected that best predicts whether an individual has diabetes/prediabetes or not within their education level. The education levels will be split as follows: 1= never attended-Grade 8, 3=Grade 9-11, 4=Grade 12-High School Graduate, 5=College Years 1-3, and 6=College year 4-College Graduate.  
# Data

We will start by reading in the data with the `read_csv` function with a relative path. 

```{r, message=FALSE}
diabetes <- read_csv("diabetes_binary_health_indicators_BRFSS2015.csv")
```

Next we will combine the 1 and 2 groups in the `Education` variable into a new group. We will do this using the `mutate` and `ifelse` functions. The new value for the 1 and 2 groups will just be 1, so `Education` can equal 1, 3, 4, 5, or 6.

```{r}
diabetes.1 <- diabetes %>% 
  mutate(Education = ifelse(Education < 3, 1, Education))
```

# Summarizations

We will start by doing some exploratory data analysis on the full data set. 

Since we will be creating models for different education levels, we will split up the data into smaller data set for each of the 5 education levels to do EDA. We will do this using our parameters
```{r}
#create subsetted data set for each level of education using the params.
diabetes.ed <- diabetes.1 %>% 
  filter(Education == params$Ed)
```  

We will also look at the graph of diabetes proportion vs their Physical Health. 
```{r}
#group by PhysHlth to create graph of proportion of people with diabetes at each number of days with illness/injury
physHlth.sum <- diabetes.ed %>% 
  group_by(PhysHlth) %>% 
  summarise(proportion.diabetes = mean(Diabetes_binary), n = n())
# create plot
ggplot(physHlth.sum, aes(x = PhysHlth, y = proportion.diabetes, size = n)) +
  geom_point(stat = "identity")+ 
#add title and labels
  xlab("Physical Illness/Injury (# of days)")+
  labs(title = "Proportion of People with Diabetes", subtitle = "vs the number of days they had a Physical illness/injury the last 30 days")
```  

```{r}
#Create a table with the proportions of people with/without diabetes vs whether they heavily drink or not
tab.Alc<- table(diabetes.ed$Diabetes_binary, diabetes.ed$HvyAlcoholConsump)
#Add Column and row names
colnames(tab.Alc)=c("No Heavy Alcohol Consumption", "Heavy Alcohol Consumption")
rownames(tab.Alc)=c("No Diabetes", "Pre-/Diabetes")
tab.Alc #printing
```  

```{r}
#create a new factor variable of the Sex variable
Gender <- factor(ifelse(diabetes.ed$Sex>0,"Female","Male"))
#group by HvyAlcoholConsump to create graph of proportion of people with diabetes vs whether they drink heavily or not and their sex
Alc.sum <- diabetes.ed %>% 
  mutate(proportion.diabetes = mean(Diabetes_binary), Gender) %>%
  group_by(HvyAlcoholConsump)
#create graph
ggplot(Alc.sum, aes(x=HvyAlcoholConsump, y=proportion.diabetes))+
  geom_bar(stat="identity", aes(fill=Gender), position="stack")
```

```{r}
#Create a table with the proportions of people with/without diabetes vs whether they had to avoid the doctor the last 30 days due to costs
tab.Doc<- prop.table(table(diabetes.ed$Diabetes_binary, diabetes.ed$NoDocbcCost))
#Add Column and row names
colnames(tab.Doc)=c("Not Avoid", "Avoid Doc")
rownames(tab.Doc)=c("No Diabetes", "Pre-/Diabetes")
tab.Doc #printing
```

```{r}
#group by NoDocbcCost to create graph of proportion of people with diabetes vs whether they avoided the doctor or not and their sex
Doc.sum <- diabetes.ed %>% 
  mutate(proportion.diabetes = mean(Diabetes_binary), Gender) %>%
  group_by(NoDocbcCost)
#create graph
ggplot(Doc.sum, aes(x=NoDocbcCost, y=proportion.diabetes))+
  geom_bar(stat="identity", aes(fill=Gender),position="stack")
```

# Modeling

Before doing any modeling we will split the data into a training and test set using the `createDataPartition` function from the `caret` package. The test/train data will be split with a 70/30 ratio.

```{r}
# makes Diabetes_binary variable a factor
diabetes.ed$Diabetes_binary <- as_factor(diabetes.ed$Diabetes_binary)
#make things reproducible with set.seed (I have no idea what number we are supposed to put here because I don't really know what this function does)
set.seed(90)
#create index
train.index <- createDataPartition(diabetes.ed$Diabetes_binary, p = .7, list = FALSE)
#create train and test sets
diabetes.train <- diabetes.ed[train.index, ]
diabetes.test <- diabetes.ed[-train.index, ]
```


# Model Selection

## Lasso  
Lasso regression can be an extension of linear regression or logistic regression. Here, we will use it with a logistic regression model since we are working with a categorical response variable.You want the lambda that gives the smallest deviance. 
```{r}
fit.lasso <- train(Diabetes_binary ~ BMI+Age+Income+MentHlth+Sex+PhysHlth+ AnyHealthcare+HvyAlcoholConsump+NoDocbcCost, 
                   data= diabetes.train,
                   method= "glmnet",
                   trControl= trainControl(method = "cv",
                                           number=5),
                   tuneGrid= expand.grid(alpha=1, lambda= seq(0,1, by=0.1)))
#print results of lasso logistic regression model
print(fit.lasso)
```
The best lasso logistic regression model is `r `.

## Classification Trees  
A classification tree is used to predict what class each region is using the most prevalent class (since we have a categorical response) as the prediction.
```{r}
fit.classtree <- train(Diabetes_binary ~ BMI+Age+Income+MentHlth+Sex+PhysHlth+ AnyHealthcare+HvyAlcoholConsump+NoDocbcCost, 
                   data= diabetes.train,
                   method= "rpart",
                   trControl= trainControl(method = "cv",
                                           number=5),
                   tuneGrid= data.frame(cp= seq(0,1, by=0.001)))
#print results of classification tree model
print(fit.classtree)
```
The best classification model is `r `.  

# Final Model Selection  
```{r, warning=FALSE}

```